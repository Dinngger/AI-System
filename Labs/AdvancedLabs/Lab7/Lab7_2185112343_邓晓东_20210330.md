# Lab 7 - 分布式训练任务练习

## 实验环境

||||
|--------|--------------|--------------------------|
|硬件环境|服务器数目|1&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |
||网卡型号、数目|Intel Corporation Ethernet Connection (7) I219|
||CPU（vCPU数目）|Intel® Core™ i7-9700K CPU @ 3.60GHz × 8  &nbsp; |
||GPU型号、数目|GeForce RTX 2070 SUPER|
||GPU连接方式|无|
|软件环境|OS版本|Ubuntu 18.04.5 LTS|
||GPU driver、(opt. NIC driver)|Nvidia Driver 450.102.04|
||深度学习框架<br>python包名称及版本|Python 3.7.6<br>PyTorch 1.5.0|
||CUDA版本|10.2|
||||

## 实验结果

||||||
|-|-|-|-|-|
|number of CPUs|number of GPUs|Batch size|Img/sec per CPU/GPU|Total img/sec on CPU(s)|
|8||4|0.5|4.4|
|8||8|0.7|5.6|
|8||16|0.8|6.6|
|4||8|1.3|5.4|
|4||16|1.7|6.7|
|4||32|1.9|7.5|
|4||64|2.0|8.1|
|2||16|2.6|5.1|
|1||32|2.6|2.6|
||1|2|102.2||
||1|4|141.5||
||1|8|188.8||
||1|16|215.3||
||1|32|237.9||
||1|64|249.9||

## 结果分析

考虑计算任务由并行部分和串行部分组成。当worker数量增大时，并行部分的吞吐量会成倍增大，而串行部分的吞吐量不变，同时增大通讯损耗。

当CPU数越少，或者Batch Size越大时，由于通讯需求减小/可并行度增加，单核的吞吐量越大。
所以当总Batch Size一定时，总吞吐量并不随着CPU数增加而一直增大，而是存在一个最大值。

同理，GPU的吞吐量也随Batch Size的增大而增大。